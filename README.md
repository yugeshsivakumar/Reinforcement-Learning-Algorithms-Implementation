# Reinforcement-Learning-Algorithms-Implementation

This project implements and compares two popular reinforcement learning algorithms: Upper Confidence Bound (UCB) and Thompson Sampling (TSA). The aim is to demonstrate and visualize the performance of these algorithms in a multi-armed bandit setting.


The following algorithms are covered:

- Upper Confidence Bound (UCB)
- Thompson Sampling (TS)

The implementation includes the simulation of a dataset, execution of both algorithms, and visualization of their cumulative rewards.

## Project Structure

```bash
/Reinforcement-Learning-Algorithms
    Reinforcement.ipynb
    README.md
```

## Requirements

To run the Jupyter notebook, you'll need the following Python packages:

* `numpy`
* `matplotlib`
* `math`

You can install the required packages using pip:

```
pip install numpy matplotlib
```

## How to Run

Clone this repository:

```
https://github.com/yugeshsivakumar/Reinforcement-Learning-Algorithms-Implementation.git

```

Navigate to the project directory:

```
cd Reinforcement-Learning-Algorithms

```

Open the Jupyter notebook:

```
jupyter notebook Reinforcement.ipynb
```

Execute the cells in the `Reinforcement.ipynb` notebook to simulate the dataset, run the algorithms, and view the results.

## Contributing

If you'd like to contribute to this project, please fork the repository and create a pull request with your proposed changes.

## License

This project is licensed under the MIT License. See the LICENSE file for details.
